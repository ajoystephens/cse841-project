{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Data Cleaning Pipeline with Raha and Baran (Minimal and Integrated)\n",
    "We build an end-to-end data cleaning pipeline with our configuration-free error detection and correction systems, Raha and Baran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import IPython.display\n",
    "import ipywidgets\n",
    "\n",
    "import raha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating the Detection and Correction Classes\n",
    "We first instantiate the `Detection` and `Correction` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1 = raha.Detection()\n",
    "app_2 = raha.Correction()\n",
    "\n",
    "# How many tuples would you label?\n",
    "app_1.LABELING_BUDGET = 20\n",
    "app_2.LABELING_BUDGET = 0\n",
    "\n",
    "# Would you like to see the logs?\n",
    "app_1.VERBOSE = True\n",
    "app_2.VERBOSE = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instantiating the Dataset\n",
    "We next load and instantiate the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>type_of_assessment</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>screening_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "      <td>2013-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>kortney coleman</td>\n",
       "      <td>kortney</td>\n",
       "      <td>coleman</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Female</td>\n",
       "      <td>1978-08-22</td>\n",
       "      <td>37</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name    first         last compas_screening_date     sex  \\\n",
       "0   3         kevon dixon    kevon        dixon            2013-01-27    Male   \n",
       "1   4            ed philo       ed        philo            2013-04-14    Male   \n",
       "2   5         marcu brown    marcu        brown            2013-01-13    Male   \n",
       "3   6  bouthy pierrelouis   bouthy  pierrelouis            2013-03-26    Male   \n",
       "4  16     kortney coleman  kortney      coleman            2013-01-01  Female   \n",
       "\n",
       "          dob age       age_cat              race  ... vr_offense_date  \\\n",
       "0  1982-01-22  34       25 - 45  African-American  ...      2013-07-05   \n",
       "1  1991-05-14  24  Less than 25  African-American  ...                   \n",
       "2  1993-01-21  23  Less than 25  African-American  ...                   \n",
       "3  1973-01-22  43       25 - 45             Other  ...                   \n",
       "4  1978-08-22  37       25 - 45         Caucasian  ...                   \n",
       "\n",
       "                vr_charge_desc v_type_of_assessment v_decile_score  \\\n",
       "0  Felony Battery (Dom Strang)     Risk of Violence              1   \n",
       "1                                  Risk of Violence              3   \n",
       "2                                  Risk of Violence              6   \n",
       "3                                  Risk of Violence              1   \n",
       "4                                  Risk of Violence              1   \n",
       "\n",
       "  v_score_text v_screening_date  type_of_assessment decile_score.1 score_text  \\\n",
       "0          Low       2013-01-27  Risk of Recidivism              3        Low   \n",
       "1          Low       2013-04-14  Risk of Recidivism              4        Low   \n",
       "2       Medium       2013-01-13  Risk of Recidivism              8       High   \n",
       "3          Low       2013-03-26  Risk of Recidivism              1        Low   \n",
       "4          Low       2013-01-01  Risk of Recidivism              1        Low   \n",
       "\n",
       "  screening_date  \n",
       "0     2013-01-27  \n",
       "1     2013-04-14  \n",
       "2     2013-01-13  \n",
       "3     2013-03-26  \n",
       "4     2013-01-01  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dictionary = {\n",
    "    \"name\": \"compas\",\n",
    "    \"path\": \"../datasets/compas/dirty_1.csv\",\n",
    "    \"clean_path\": \"../datasets/compas/clean_1.csv\"\n",
    "}\n",
    "d = app_1.initialize_dataset(dataset_dictionary)\n",
    "d.dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Features and Clusters\n",
    "Raha runs (all or the promising) error detection strategies on the dataset. This step could take a while because all the strategies should be run on the dataset. Raha then generates a feature vector for each data cell based on the output of error detection strategies. Raha next builds a hierarchical clustering model for our clustering-based sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/Users/annastephens/Source/cse841-project/venv/lib/python3.11/site-packages/raha/detection.py\", line 92, in _strategy_runner_process\n    for i, value in d.dataframe[attribute].iteritems():\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/annastephens/Source/cse841-project/venv/lib/python3.11/site-packages/pandas/core/generic.py\", line 5989, in __getattr__\n    return object.__getattribute__(self, name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'Series' object has no attribute 'iteritems'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_strategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m app_1\u001b[38;5;241m.\u001b[39mgenerate_features(d)\n\u001b[1;32m      3\u001b[0m app_1\u001b[38;5;241m.\u001b[39mbuild_clusters(d)\n",
      "File \u001b[0;32m~/Source/cse841-project/venv/lib/python3.11/site-packages/raha/detection.py:189\u001b[0m, in \u001b[0;36mDetection.run_strategies\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    187\u001b[0m         random\u001b[38;5;241m.\u001b[39mshuffle(algorithm_and_configurations)\n\u001b[1;32m    188\u001b[0m         pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool()\n\u001b[0;32m--> 189\u001b[0m         strategy_profiles_list \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy_runner_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm_and_configurations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# pool.close()\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# pool.join()\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dd \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mHISTORICAL_DATASETS \u001b[38;5;241m+\u001b[39m [d\u001b[38;5;241m.\u001b[39mdictionary]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "app_1.run_strategies(d)\n",
    "app_1.generate_features(d)\n",
    "app_1.build_clusters(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Tuple Sampling and Labeling\n",
    "Raha then iteratively samples a tuple. We should label data cells of each sampled tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def on_button_clicked(_):\n",
    "    for j in range(0, len(texts)):\n",
    "        cell = (d.sampled_tuple, j)\n",
    "        error_label = 0\n",
    "        correction = texts[j].value\n",
    "        if d.dataframe.iloc[cell] != correction:\n",
    "            error_label = 1\n",
    "        d.labeled_cells[cell] = [error_label, correction]\n",
    "    d.labeled_tuples[d.sampled_tuple] = 1\n",
    "\n",
    "app_1.sample_tuple(d)\n",
    "print(\"Fix the dirty cells in the following sampled tuple.\")\n",
    "sampled_tuple = pandas.DataFrame(data=[d.dataframe.iloc[d.sampled_tuple, :]], columns=d.dataframe.columns)\n",
    "IPython.display.display(sampled_tuple)  \n",
    "texts = [ipywidgets.Text(value=d.dataframe.iloc[d.sampled_tuple, j]) for j in range(d.dataframe.shape[1])]\n",
    "button = ipywidgets.Button(description=\"Save the Annotation\")\n",
    "button.on_click(on_button_clicked)\n",
    "output = ipywidgets.VBox(children=texts + [button])\n",
    "IPython.display.display(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of time, we use the ground truth of the dataset to label tuples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "while len(d.labeled_tuples) < app_1.LABELING_BUDGET:\n",
    "    app_1.sample_tuple(d)\n",
    "    if d.has_ground_truth:\n",
    "        app_1.label_with_ground_truth(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Propagating User Labels and Predicting the Labels\n",
    "Raha then propagates each user label through its cluster. Raha then trains and applies one classifier per data column to predict the label of the rest of data cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1.propagate_labels(d)\n",
    "app_1.predict_labels(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initializing and Updating the Error Corrector Models\n",
    "Baran initializes the error corrector models. Baran then iteratively samples a tuple. We should label data cells of each sampled tuple. It then udpates the models accordingly and generates a feature vector for each pair of a data error and a correction candidate. Finally, it trains and applies a classifier to each data column to predict the final correction of each data error. Since we already labeled tuples for Raha, we use the same labeled tuples and do not label new tuples here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_2.initialize_models(d)\n",
    "app_2.initialize_dataset(d)\n",
    "for si in d.labeled_tuples:\n",
    "    d.sampled_tuple = si\n",
    "    app_2.update_models(d)\n",
    "    app_2.predict_corrections(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Storing Results\n",
    "Both Raha and Baran can also store the error detection/correction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1.store_results(d)\n",
    "app_2.store_results(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluating the Data Cleaning Task\n",
    "We can finally evaluate our data cleaning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edp, edr, edf = d.get_data_cleaning_evaluation(d.detected_cells)[:3]\n",
    "ecp, ecr, ecf = d.get_data_cleaning_evaluation(d.corrected_cells)[-3:]\n",
    "\n",
    "evaluation_df = pandas.DataFrame(columns=[\"Task\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "evaluation_detection_df = pandas.DataFrame({\"Task\": \"Error Detection (Raha)\", \"Precision\": \"{:.2f}\".format(edp), \"Recall\": \"{:.2f}\".format(edr), \"F1 Score\": \"{:.2f}\".format(edf)}, index=[0])\n",
    "evaluation_correction_df = pandas.DataFrame({\"Task\": \"Error Correction (Baran)\", \"Precision\": \"{:.2f}\".format(ecp), \"Recall\": \"{:.2f}\".format(ecr), \"F1 Score\": \"{:.2f}\".format(ecf)}, index=[0])\n",
    "evaluation_df = pandas.concat([evaluation_df, evaluation_detection_df, evaluation_correction_df], ignore_index=True)\n",
    "evaluation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
